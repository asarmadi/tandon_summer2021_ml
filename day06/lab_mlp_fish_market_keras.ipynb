{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPhD3tBWYP9G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTHIFLwUYP9b"
   },
   "source": [
    "### Load and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOf98xw7YP9d"
   },
   "outputs": [],
   "source": [
    "feature = pd.read_csv('https://raw.githubusercontent.com/BolunDai0216/nyuMLSummerSchool21/master/day05/fish_market_feature.csv')\n",
    "label = pd.read_csv('https://raw.githubusercontent.com/BolunDai0216/nyuMLSummerSchool21/master/day05/fish_market_label.csv')\n",
    "X = feature.values\n",
    "y = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data using sklearn's StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# split the SCALED!! data in validation and train\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(..., test_size=0.1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# print the number of data samples in the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXd-R6M1YP9s"
   },
   "source": [
    "### Build Model\n",
    "\n",
    "1) Define a model of three dense layers with ReLu activation functions. The output of the two first layers should have 32 neurons. \n",
    "\n",
    "2) Train the model for 2000 epochs with a batch size of 64 and a mean squared error loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlKXS0cMeMcp"
   },
   "outputs": [],
   "source": [
    "## TODO\n",
    "n_epochs = 2000\n",
    "batch_size = 64\n",
    "\n",
    "model = Sequential([...])\n",
    "model.compile(...) # use the Adam optimizer\n",
    "\n",
    "# print a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# train the model (use the train data and validation data from above)\n",
    "history = model.fit(..., validation_data=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# plot the train and validation losses on the same picture\n",
    "# make sure to label the axis and create a legend "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6kC3IVHYP-E"
   },
   "source": [
    "#### Load the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWgUAW_mYP-F"
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('https://raw.githubusercontent.com/BolunDai0216/nyuMLSummerSchool21/master/day05/fish_market_test_feature.csv').values\n",
    "y_test = pd.read_csv('https://raw.githubusercontent.com/BolunDai0216/nyuMLSummerSchool21/master/day05/fish_market_test_label.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the test data using the scaler above\n",
    "Xtest_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# predict the corresponding y_hat value of the test dataset (use the scaled test data)\n",
    "y_hat = model.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "A8hiFtuwYP-P",
    "outputId": "6a8fa4a7-9dcc-46dc-a235-29687397f4e7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(np.arange(y_hat.shape[0]), y_hat, label='Prediction')\n",
    "plt.scatter(np.arange(y_test.shape[0]), y_test, label='Ground Truth')\n",
    "plt.legend()\n",
    "plt.xlabel('data no.')\n",
    "plt.ylabel('predicted value')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# print MSE, RMSE (root-mse), MAE on the train and test data\n",
    "# compare these results against last week's results (when we used linear/polynimial regression)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_mlp_fish_market_keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
